---
title: HMM学习笔记4——评估问题
mathjax: true
date: 2023-02-19 14:31:51
categories: HMM
description: 评估问题是HMM常见的三大问题之一，通常使用前向算法和后向算法解决。
---

## 问题描述

HMM中的评估问题通常为给定一个$\lambda=(\pi,A,B)$，求得到某个指定的观测序列$V$的概率。

这里我们不妨使用$T$代表观测序列$V$的长度。

## 方法一：暴力

鲁迅有言：暴力出奇迹。对于评估问题来说，我们穷举所有可能的隐藏序列，并计算每一种隐藏序列得到指定观测序列的概率，从而计算整个$\lambda$得到特定观测序列的概率。

以下图为例：

![网格](HMM学习笔记4——评估问题/trellis.gif)

如果指定的观测序列为$\set{dry,damp,soggy}$，那么不难发现总共有$3^3=27$种可能的状态序列，比如$\set{sunny,sunny,sunny},\set{sunny,sunny,cloudy}$等等，接下来我们对这27种可能的状态序列$Q$计算$P(V|Q_{i})$，那么$P(V|\lambda)=\sum P(Q|\lambda)\times P(V|Q)$

这种算法的问题是$O(TN^{T})$时间复杂度太高了，现实中很难在规定时间内求出。

## 方法二：前向算法

我们曾说HMM有齐次性这一特性，这一点与DP所要求的状态无后效性相似，因此我们可以尝试使用DP来进行评估问题的求解，即前向算法。

对于给定的$\lambda$，我们定义到时刻$t$时的观测序列为$\set{o_1,o_2,o_3\dots o_t}$（即给定观测序列的前$t$项）且当前状态为$q_i$的概率为前向概率$\alpha_t(i)$，记为$\alpha_t(i)=P(\set{o_1,o_2,o_3\dots o_t},i_t=q_i|\lambda)$。

对于前向概率$\alpha$的计算我们可以按如下三步进行：

1. 计算初始值：$\alpha_1(i)=\pi_ib_i(o_1),i\in[1,N]$
2. 递推计算：$\alpha_{t+1}(i)=[\sum_{j=1}^N \alpha_t(j)\times a_{ji}]b_i(o_{t+1})$，$t\in[1,T-1]$，其中$j$表示$t$时刻状态为$q_j$
3. 求最终结果：$P(O|\lambda)=\sum_{i=1}^{N} \alpha_T(i)$

这个算法的时间复杂度为$O(TN^{2})$，在可接受范围内。

## 方法三：后向算法

如果能理解前向算法的化那后向算法理解起来应该十分简单，其也是基于了动态规划的思想。

我们定义后向概率为在时刻$t$，如果当前状态为$q_i$，则从时刻$t+1$到时刻$T$的预测序列为$\set{o_{t+1},o_{t+2},\dots,o_T}$的概率，即$\beta_t{i}=P(\set{o_{t+1},o_{t+2},\dots,o_T}|i_t=q_i,\lambda)$

后向算法按如下三步进行：

1. 初始化后向概率：因为最后得到的是给定的观测序列，所以$\beta_T{(i)}=1$，$i\in[1,N]$
2. 递推计算：$\beta_t(i)=[\sum_{j=1}^{N} \beta_{t+1}(j)\times a_{ij}]b_{j}(o_{t+1})$，$t\in[1,T-1]$
3. 求最终结果：$P(O|\lambda)=\sum_{i=1}^{N}\pi_{i}\times \beta_{1}(i)\times b_{i}(o_{1})$

